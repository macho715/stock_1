import pandas as pd
import numpy as np
from datetime import datetime, date
from collections import defaultdict, Counter
import openpyxl
from openpyxl.utils.dataframe import dataframe_to_rows
import re
import warnings
warnings.filterwarnings('ignore')

class InventoryTracker:
    def __init__(self, excel_file_path):
        """
        ì°½ê³  ì¬ê³  ì¶”ì  ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            excel_file_path (str): Excel íŒŒì¼ ê²½ë¡œ
        """
        self.excel_file = excel_file_path
        self.workbook = None
        self.case_data = defaultdict(list)  # CASE -> [(date, location), ...]
        self.out_data = defaultdict(list)   # ì¶œê³  ë°ì´í„°
        self.global_max_date = None
        
        # ì»¬ëŸ¼ ë§¤í•‘ (VBAì™€ ë™ì¼: B=2, D=4, H=8 -> 0-based index)
        self.CASE_COL = 1    # Column B (0-based: 1)
        self.LOCATION_COL = 3  # Column D (0-based: 3)  
        self.DATE_COL = 7    # Column H (0-based: 7)
    
    def load_workbook(self):
        """Excel ì›Œí¬ë¶ ë¡œë“œ"""
        try:
            self.workbook = pd.ExcelFile(self.excel_file)
            print(f"âœ… ì›Œí¬ë¶ ë¡œë“œ ì™„ë£Œ: {len(self.workbook.sheet_names)}ê°œ ì‹œíŠ¸ ë°œê²¬")
            return True
        except Exception as e:
            print(f"âŒ ì›Œí¬ë¶ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def normalize_date(self, date_val, current_year=2024):
        """ë‚ ì§œ ì •ê·œí™”: yyyy-mm-dd í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        if pd.isna(date_val) or date_val == "":
            return ""
        
        try:
            if isinstance(date_val, (datetime, date)):
                return date_val.strftime('%Y-%m-%d')
            elif isinstance(date_val, str):
                date_val = date_val.strip()
                if date_val == "":
                    return ""
                
                # "16-Feb", "23-Apr" í˜•ì‹ ì²˜ë¦¬ (ë…„ë„ ì—†ëŠ” ê²½ìš°)
                if re.match(r'^\d{1,2}-[A-Za-z]{3}$', date_val):
                    try:
                        # í˜„ì¬ ë…„ë„ ì¶”ê°€í•˜ì—¬ íŒŒì‹±
                        full_date = f"{date_val}-{current_year}"
                        parsed_date = pd.to_datetime(full_date, format='%d-%b-%Y')
                        return parsed_date.strftime('%Y-%m-%d')
                    except:
                        pass
                
                # ì¼ë°˜ì ì¸ ë‚ ì§œ í˜•ì‹ ì²˜ë¦¬
                parsed_date = pd.to_datetime(date_val)
                return parsed_date.strftime('%Y-%m-%d')
            else:
                parsed_date = pd.to_datetime(str(date_val))
                return parsed_date.strftime('%Y-%m-%d')
        except:
            return ""
    
    def is_out_sheet(self, sheet_name):
        """ì¶œê³  ì‹œíŠ¸ íŒë³„: ì´ë¦„ì— OUT ë˜ëŠ” DISPATCH í¬í•¨"""
        sheet_upper = sheet_name.upper()
        return 'OUT' in sheet_upper or 'DISPATCH' in sheet_upper
    
    def process_sheet(self, sheet_name):
        """ê°œë³„ ì‹œíŠ¸ ì²˜ë¦¬ - í†µí•©ë¶„ì„ íŒŒì¼ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •"""
        try:
            # ì‹œíŠ¸ ë°ì´í„° ë¡œë“œ (í—¤ë” 1í–‰, ë°ì´í„° 2í–‰ë¶€í„°)
            df = pd.read_excel(self.excel_file, sheet_name=sheet_name, header=0)
            
            print(f"ğŸ“‹ {sheet_name} ì²˜ë¦¬ ì¤‘... (í–‰: {len(df)}, ì—´: {len(df.columns)})")
            print(f"   ì»¬ëŸ¼: {list(df.columns)}")
            
            # ì‹œíŠ¸ë³„ë¡œ ë‹¤ë¥¸ ì²˜ë¦¬ ë¡œì§ ì ìš©
            if sheet_name == "ì¢…í•©_SKUìš”ì•½":
                processed_count = self.process_sku_summary_sheet(df, sheet_name)
            elif sheet_name == "ë‚ ì§œë³„_ì¶”ì´":
                processed_count = self.process_date_trend_sheet(df, sheet_name)
            elif sheet_name == "ì›”ë³„_ë¶„ì„":
                processed_count = self.process_monthly_analysis_sheet(df, sheet_name)
            elif sheet_name == "ì°½ê³ ë³„_í˜„í™©":
                processed_count = self.process_warehouse_status_sheet(df, sheet_name)
            elif sheet_name == "ë¶„ì„_í†µê³„":
                processed_count = self.process_statistics_sheet(df, sheet_name)
            else:
                # ê¸°ì¡´ ë¡œì§ ìœ ì§€ (ì¼ë°˜ ì¬ê³  ì‹œíŠ¸ìš©)
                processed_count = self.process_general_sheet(df, sheet_name)
            
            sheet_type = "ì¶œê³ " if self.is_out_sheet(sheet_name) else "ì…ê³ "
            print(f"   âœ… {processed_count}ê±´ ì²˜ë¦¬ ì™„ë£Œ ({sheet_type})")
            
        except Exception as e:
            print(f"âŒ {sheet_name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            import traceback
            print(f"   ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
    
    def process_sku_summary_sheet(self, df, sheet_name):
        """ì¢…í•©_SKUìš”ì•½ ì‹œíŠ¸ ì²˜ë¦¬"""
        processed_count = 0
        
        for idx, row in df.iterrows():
            if pd.notna(row['SKU']):
                case_no = str(row['SKU']).strip()
                location = str(row['Last_Location']).strip() if pd.notna(row['Last_Location']) else ""
                date_raw = row['Last_Seen'] if pd.notna(row['Last_Seen']) else ""
                date_normalized = self.normalize_date(date_raw)
                
                if case_no and case_no.lower() != 'nan':
                    entry = (date_normalized, location)
                    
                    # ìƒíƒœì— ë”°ë¼ ì…ê³ /ì¶œê³  ë¶„ë¥˜
                    if 'OUT' in str(row.get('Status', '')):
                        if entry not in self.out_data[case_no]:
                            self.out_data[case_no].append(entry)
                            processed_count += 1
                    else:
                        if entry not in self.case_data[case_no]:
                            self.case_data[case_no].append(entry)
                            processed_count += 1
        
        return processed_count
    
    def process_date_trend_sheet(self, df, sheet_name):
        """ë‚ ì§œë³„_ì¶”ì´ ì‹œíŠ¸ ì²˜ë¦¬"""
        processed_count = 0
        
        for idx, row in df.iterrows():
            if pd.notna(row['Date']):
                case_no = f"ë‚ ì§œì¶”ì´_{row['Date'].strftime('%Y-%m-%d')}"
                location = f"SKUìˆ˜ëŸ‰:{row['SKU_Count']}"
                date_raw = row['Date']
                date_normalized = self.normalize_date(date_raw)
                
                entry = (date_normalized, location)
                if entry not in self.case_data[case_no]:
                    self.case_data[case_no].append(entry)
                    processed_count += 1
        
        return processed_count
    
    def process_monthly_analysis_sheet(self, df, sheet_name):
        """ì›”ë³„_ë¶„ì„ ì‹œíŠ¸ ì²˜ë¦¬"""
        processed_count = 0
        
        for idx, row in df.iterrows():
            if pd.notna(row['Month_Key']):
                case_no = str(row['Month_Key']).strip()
                location = f"IN:{row['Total_IN']}_OUT:{row['Total_OUT']}"
                # ì›” í‚¤ë¥¼ ë‚ ì§œë¡œ ë³€í™˜ (ì˜ˆ: 2024-06 -> 2024-06-01)
                date_raw = f"{row['Month_Key']}-01"
                date_normalized = self.normalize_date(date_raw)
                
                entry = (date_normalized, location)
                if entry not in self.case_data[case_no]:
                    self.case_data[case_no].append(entry)
                    processed_count += 1
        
        return processed_count
    
    def process_warehouse_status_sheet(self, df, sheet_name):
        """ì°½ê³ ë³„_í˜„í™© ì‹œíŠ¸ ì²˜ë¦¬"""
        processed_count = 0
        
        for idx, row in df.iterrows():
            if pd.notna(row['Warehouse']):
                case_no = f"ì°½ê³ _{row['Warehouse']}"
                location = f"í˜„ì¬ì¬ê³ :{row['Current_Stock']}_ì´ì´ë ¥:{row['Total_Historical']}"
                date_normalized = datetime.now().strftime('%Y-%m-%d')  # í˜„ì¬ ë‚ ì§œ ì‚¬ìš©
                
                entry = (date_normalized, location)
                if entry not in self.case_data[case_no]:
                    self.case_data[case_no].append(entry)
                    processed_count += 1
        
        return processed_count
    
    def process_statistics_sheet(self, df, sheet_name):
        """ë¶„ì„_í†µê³„ ì‹œíŠ¸ ì²˜ë¦¬"""
        processed_count = 0
        
        for idx, row in df.iterrows():
            if pd.notna(row.iloc[0]) and pd.notna(row.iloc[1]):
                key = str(row.iloc[0]).strip()
                value = str(row.iloc[1]).strip()
                
                if key and key != 'nan' and value and value != 'nan':
                    case_no = f"í†µê³„_{key}"
                    location = value
                    date_normalized = datetime.now().strftime('%Y-%m-%d')  # í˜„ì¬ ë‚ ì§œ ì‚¬ìš©
                    
                    entry = (date_normalized, location)
                    if entry not in self.case_data[case_no]:
                        self.case_data[case_no].append(entry)
                        processed_count += 1
        
        return processed_count
    
    def process_general_sheet(self, df, sheet_name):
        """ì¼ë°˜ ì¬ê³  ì‹œíŠ¸ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§)"""
        processed_count = 0
        
        if len(df.columns) <= max(self.CASE_COL, self.LOCATION_COL, self.DATE_COL):
            print(f"âš ï¸  {sheet_name}: ì»¬ëŸ¼ ìˆ˜ ë¶€ì¡± (í•„ìš”: {max(self.CASE_COL, self.LOCATION_COL, self.DATE_COL)+1}, ì‹¤ì œ: {len(df.columns)}), ê±´ë„ˆëœ€")
            return 0
        
        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ (ì•ˆì „í•˜ê²Œ)
        case_col = df.iloc[:, self.CASE_COL] if len(df.columns) > self.CASE_COL else pd.Series()
        location_col = df.iloc[:, self.LOCATION_COL] if len(df.columns) > self.LOCATION_COL else pd.Series()
        date_col = df.iloc[:, self.DATE_COL] if len(df.columns) > self.DATE_COL else pd.Series()
        
        # ë¹ˆ CASE_NO ì œê±°
        valid_rows = case_col.notna() & (case_col.astype(str).str.strip() != '')
        
        is_out = self.is_out_sheet(sheet_name)
        
        for idx in df.index[valid_rows]:
            case_no = str(case_col.iloc[idx]).strip()
            location = str(location_col.iloc[idx]).strip() if idx < len(location_col) and pd.notna(location_col.iloc[idx]) else ""
            date_raw = date_col.iloc[idx] if idx < len(date_col) else ""
            date_normalized = self.normalize_date(date_raw)
            
            if case_no and case_no.lower() != 'nan':
                entry = (date_normalized, location)
                
                if is_out:
                    # ì¶œê³  ë°ì´í„°ì— ì¤‘ë³µ ì²´í¬ í›„ ì¶”ê°€
                    if entry not in self.out_data[case_no]:
                        self.out_data[case_no].append(entry)
                        processed_count += 1
                else:
                    # ì…ê³  ë°ì´í„°ì— ì¤‘ë³µ ì²´í¬ í›„ ì¶”ê°€
                    if entry not in self.case_data[case_no]:
                        self.case_data[case_no].append(entry)
                        processed_count += 1
        
        return processed_count
    
    def calculate_global_max_date(self):
        """ì „ì—­ ìµœì‹  ë‚ ì§œ ê³„ì‚° (ì…ê³  ë°ì´í„° ê¸°ì¤€)"""
        max_date = None
        
        for case_entries in self.case_data.values():
            for date_str, _ in case_entries:
                try:
                    current_date = datetime.strptime(date_str, '%Y-%m-%d').date()
                    if max_date is None or current_date > max_date:
                        max_date = current_date
                except:
                    continue
        
        self.global_max_date = max_date
        if max_date:
            print(f"ğŸ—“ï¸  ì „ì—­ ìµœì‹  ìŠ¤ëƒ…ìƒ· ë‚ ì§œ: {max_date}")
    
    def determine_status(self, case_no, in_entries, out_entries):
        """ì¬ê³  ìƒíƒœ ê²°ì •"""
        if out_entries:
            # ì¶œê³  ê¸°ë¡ì´ ìˆìœ¼ë©´ OUT
            out_dates = [entry[0] for entry in out_entries if entry[0]]
            return "OUT (by OUTsheet)", f"OutDates: {', '.join(out_dates)}"
        
        elif in_entries:
            # ì…ê³  ê¸°ë¡ë§Œ ìˆëŠ” ê²½ìš° - ìµœì‹  ìŠ¤ëƒ…ìƒ·ê³¼ ë¹„êµ
            sorted_entries = sorted(in_entries, key=lambda x: x[0])
            last_seen_str = sorted_entries[-1][0]
            
            try:
                last_seen_date = datetime.strptime(last_seen_str, '%Y-%m-%d').date()
                
                if self.global_max_date and last_seen_date < self.global_max_date:
                    return "OUT (absent in latest snapshot)", \
                           f"LastSeen: {last_seen_str} ; GlobalLatest: {self.global_max_date}"
                else:
                    return "IN", ""
            except:
                return "IN", ""
        
        else:
            return "UNKNOWN", ""
    
    def create_summary(self):
        """ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±"""
        # ëª¨ë“  CASE ìˆ˜ì§‘
        all_cases = set(self.case_data.keys()) | set(self.out_data.keys())
        
        summary_data = []
        
        for case_no in sorted(all_cases):
            in_entries = sorted(self.case_data.get(case_no, []), key=lambda x: x[0])
            out_entries = sorted(self.out_data.get(case_no, []), key=lambda x: x[0])
            
            # ê¸°ë³¸ ì •ë³´
            count = len(in_entries)
            first_in_date = in_entries[0][0] if in_entries else ""
            all_in_dates = ", ".join([entry[0] for entry in in_entries])
            last_seen = in_entries[-1][0] if in_entries else ""
            last_location = in_entries[-1][1] if in_entries else ""
            
            # ìƒíƒœ ê²°ì •
            status, note = self.determine_status(case_no, in_entries, out_entries)
            
            summary_data.append({
                'CASE_NO': case_no,
                'Count': count,
                'First_IN_Date': first_in_date,
                'All_IN_Dates': all_in_dates,
                'LastSeen': last_seen,
                'Last_Location': last_location,
                'Status': status,
                'Note': note
            })
        
        return pd.DataFrame(summary_data)
    
    def save_summary_to_excel(self, output_file=None):
        """ìš”ì•½ ê²°ê³¼ë¥¼ Excel íŒŒì¼ë¡œ ì €ì¥"""
        if output_file is None:
            output_file = self.excel_file.replace('.xlsx', '_with_summary.xlsx')
        
        try:
            # ê¸°ì¡´ ì›Œí¬ë¶ ë³µì‚¬
            wb = openpyxl.load_workbook(self.excel_file)
            
            # ê¸°ì¡´ Onhand_Summary ì‹œíŠ¸ ì‚­ì œ (ìˆë‹¤ë©´)
            if 'Onhand_Summary' in wb.sheetnames:
                wb.remove(wb['Onhand_Summary'])
            
            # ìƒˆ ìš”ì•½ ì‹œíŠ¸ ìƒì„±
            summary_df = self.create_summary()
            ws = wb.create_sheet('Onhand_Summary')
            
            # ë°ì´í„°í”„ë ˆì„ì„ ì‹œíŠ¸ì— ì“°ê¸°
            for r in dataframe_to_rows(summary_df, index=False, header=True):
                ws.append(r)
            
            # ì»¬ëŸ¼ ë„ˆë¹„ ìë™ ì¡°ì •
            for column in ws.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = min(max_length + 2, 50)
                ws.column_dimensions[column_letter].width = adjusted_width
            
            wb.save(output_file)
            print(f"âœ… ìš”ì•½ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_file}")
            print(f"ğŸ“Š ì´ {len(summary_df)}ê±´ ì²˜ë¦¬")
            return output_file
            
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return None
    
    def run_analysis(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        print("ğŸš€ ì¬ê³  ì¶”ì  ë¶„ì„ ì‹œì‘...")
        
        # 1. ì›Œí¬ë¶ ë¡œë“œ
        if not self.load_workbook():
            return None
        
        # 2. ëª¨ë“  ì‹œíŠ¸ ì²˜ë¦¬
        print("\nğŸ“‚ ì‹œíŠ¸ ì²˜ë¦¬ ì¤‘...")
        for sheet_name in self.workbook.sheet_names:
            if sheet_name not in ['Onhand_Summary']:  # ìš”ì•½ ì‹œíŠ¸ ì œì™¸
                self.process_sheet(sheet_name)
        
        # 3. ì „ì—­ ìµœì‹  ë‚ ì§œ ê³„ì‚°
        print("\nğŸ“… ë‚ ì§œ ë¶„ì„ ì¤‘...")
        self.calculate_global_max_date()
        
        # 4. ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„± ë° ì €ì¥
        print("\nğŸ“‹ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        return self.save_summary_to_excel()
    
    def get_status_summary(self):
        """ìƒíƒœë³„ ìš”ì•½ í†µê³„"""
        summary_df = self.create_summary()
        status_counts = summary_df['Status'].value_counts()
        
        print("\nğŸ“ˆ ìƒíƒœë³„ í†µê³„:")
        for status, count in status_counts.items():
            print(f"   {status}: {count}ê±´")
        
        return status_counts


# ì‚¬ìš© ì˜ˆì‹œ ë° ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def main(excel_file_path, output_file=None):
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    
    Args:
        excel_file_path (str): ë¶„ì„í•  Excel íŒŒì¼ ê²½ë¡œ
        output_file (str): ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)
    
    Returns:
        str: ìƒì„±ëœ ìš”ì•½ íŒŒì¼ ê²½ë¡œ
    """
    print("=" * 60)
    print("ğŸ­ HVDC í”„ë¡œì íŠ¸ ì¬ê³  ì¶”ì  ì‹œìŠ¤í…œ v2.0")
    print("=" * 60)
    
    tracker = InventoryTracker(excel_file_path)
    
    # ë¶„ì„ ì‹¤í–‰
    result_file = tracker.run_analysis()
    
    if result_file:
        # ìƒíƒœë³„ í†µê³„ ì¶œë ¥
        status_counts = tracker.get_status_summary()
        
        # ìš”ì•½ ë°ì´í„°í”„ë ˆì„ ë¯¸ë¦¬ë³´ê¸°
        summary_df = tracker.create_summary()
        print(f"\nğŸ“‹ ìš”ì•½ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 10ê±´):")
        print(summary_df.head(10).to_string(index=False))
        
        # ì¤‘ìš” í†µê³„
        print(f"\nğŸ“Š í•µì‹¬ í†µê³„:")
        print(f"   ğŸ“¦ ì´ ì²˜ë¦¬ CASE ìˆ˜: {len(summary_df)}")
        print(f"   ğŸ“¥ ì´ ì…ê³  ê±´ìˆ˜: {sum(len(entries) for entries in tracker.case_data.values())}")
        print(f"   ğŸ“¤ ì´ ì¶œê³  ê±´ìˆ˜: {sum(len(entries) for entries in tracker.out_data.values())}")
        print(f"   ğŸ”„ ì²˜ë¦¬ëœ ì‹œíŠ¸ ìˆ˜: {len(tracker.workbook.sheet_names) - 1}")  # ìš”ì•½ì‹œíŠ¸ ì œì™¸
        
        # ì¶œë ¥ íŒŒì¼ ì´ë¦„ ë³€ê²½ (ìš”ì²­ì‹œ)
        if output_file and output_file != result_file:
            try:
                import shutil
                shutil.copy2(result_file, output_file)
                print(f"   ğŸ“ ìµœì¢… íŒŒì¼: {output_file}")
                return output_file
            except Exception as e:
                print(f"   âš ï¸ íŒŒì¼ ë³µì‚¬ ì‹¤íŒ¨: {e}, ì›ë³¸ ì‚¬ìš©: {result_file}")
        
        return result_file
    else:
        print("âŒ ë¶„ì„ ì‹¤íŒ¨")
        return None

def analyze_hvdc_inventory(file_path, show_details=True):
    """
    HVDC í”„ë¡œì íŠ¸ ì „ìš© ì¬ê³  ë¶„ì„ í•¨ìˆ˜
    
    Args:
        file_path (str): Excel íŒŒì¼ ê²½ë¡œ
        show_details (bool): ìƒì„¸ ì •ë³´ ì¶œë ¥ ì—¬ë¶€
    """
    print("ğŸ” HVDC ì¬ê³  ìƒì„¸ ë¶„ì„ ì‹œì‘...")
    
    tracker = InventoryTracker(file_path)
    
    if not tracker.load_workbook():
        return None
    
    # ì‹œíŠ¸ë³„ ìƒì„¸ ë¶„ì„
    sheet_analysis = {}
    for sheet_name in tracker.workbook.sheet_names:
        if sheet_name != 'Onhand_Summary':
            tracker.process_sheet(sheet_name)
            
            # ì‹œíŠ¸ë³„ í†µê³„
            case_count = len([case for case, entries in tracker.case_data.items() if any(sheet_name in str(e) for e in entries)])
            sheet_analysis[sheet_name] = {
                'type': 'ì¶œê³ ' if tracker.is_out_sheet(sheet_name) else 'ì…ê³ ',
                'case_count': case_count
            }
    
    if show_details:
        print(f"\nğŸ“Š ì‹œíŠ¸ë³„ ë¶„ì„ ê²°ê³¼:")
        for sheet, info in sheet_analysis.items():
            print(f"   {sheet} ({info['type']}): {info['case_count']}ê°œ CASE")
    
    tracker.calculate_global_max_date()
    summary_file = tracker.save_summary_to_excel()
    
    return summary_file

# ì§ì ‘ ì‹¤í–‰ ì‹œ í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    # ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ
    print("ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
    print("ì‹¤ì œ ì‚¬ìš©ë²•:")
    print("   result = main('your_inventory_file.xlsx')")
    print("   ë˜ëŠ”")  
    print("   result = analyze_hvdc_inventory('your_inventory_file.xlsx')")
    
    # ì‹¤ì œ íŒŒì¼ì´ ìˆë‹¤ë©´ ì£¼ì„ í•´ì œ
    # test_file = "hvdc_inventory.xlsx"
    # result = main(test_file)
    
    # if result:
    #     print(f"\nğŸ‰ ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ íŒŒì¼: {result}")
    
    def is_out_sheet(self, sheet_name):
        """ì¶œê³  ì‹œíŠ¸ íŒë³„: ì´ë¦„ì— OUT ë˜ëŠ” DISPATCH í¬í•¨"""
        sheet_upper = sheet_name.upper()
        return 'OUT' in sheet_upper or 'DISPATCH' in sheet_upper
    
    def process_sheet(self, sheet_name):
        """ê°œë³„ ì‹œíŠ¸ ì²˜ë¦¬"""
        try:
            # ì‹œíŠ¸ ë°ì´í„° ë¡œë“œ (í—¤ë” 1í–‰, ë°ì´í„° 2í–‰ë¶€í„°)
            df = pd.read_excel(self.excel_file, sheet_name=sheet_name, header=0)
            
            if len(df.columns) <= max(self.CASE_COL, self.LOCATION_COL, self.DATE_COL):
                print(f"âš ï¸  {sheet_name}: ì»¬ëŸ¼ ìˆ˜ ë¶€ì¡±, ê±´ë„ˆëœ€")
                return
            
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
            df_filtered = df.iloc[:, [self.CASE_COL, self.LOCATION_COL, self.DATE_COL]]
            df_filtered.columns = ['CASE_NO', 'LOCATION', 'DATE_RECEIVE']
            
            # ë¹ˆ CASE_NO ì œê±°
            df_filtered = df_filtered[df_filtered['CASE_NO'].notna()]
            df_filtered = df_filtered[df_filtered['CASE_NO'].astype(str).str.strip() != '']
            
            is_out = self.is_out_sheet(sheet_name)
            processed_count = 0
            
            for _, row in df_filtered.iterrows():
                case_no = str(row['CASE_NO']).strip()
                location = str(row['LOCATION']).strip() if pd.notna(row['LOCATION']) else ""
                date_normalized = self.normalize_date(row['DATE_RECEIVE'])
                
                if case_no and date_normalized:
                    entry = (date_normalized, location)
                    
                    if is_out:
                        # ì¶œê³  ë°ì´í„°ì— ì¤‘ë³µ ì²´í¬ í›„ ì¶”ê°€
                        if entry not in self.out_data[case_no]:
                            self.out_data[case_no].append(entry)
                            processed_count += 1
                    else:
                        # ì…ê³  ë°ì´í„°ì— ì¤‘ë³µ ì²´í¬ í›„ ì¶”ê°€
                        if entry not in self.case_data[case_no]:
                            self.case_data[case_no].append(entry)
                            processed_count += 1
            
            sheet_type = "ì¶œê³ " if is_out else "ì…ê³ "
            print(f"ğŸ“‹ {sheet_name} ({sheet_type}): {processed_count}ê±´ ì²˜ë¦¬")
            
        except Exception as e:
            print(f"âŒ {sheet_name} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    def calculate_global_max_date(self):
        """ì „ì—­ ìµœì‹  ë‚ ì§œ ê³„ì‚° (ì…ê³  ë°ì´í„° ê¸°ì¤€)"""
        max_date = None
        
        for case_entries in self.case_data.values():
            for date_str, _ in case_entries:
                try:
                    current_date = datetime.strptime(date_str, '%Y-%m-%d').date()
                    if max_date is None or current_date > max_date:
                        max_date = current_date
                except:
                    continue
        
        self.global_max_date = max_date
        if max_date:
            print(f"ğŸ—“ï¸  ì „ì—­ ìµœì‹  ìŠ¤ëƒ…ìƒ· ë‚ ì§œ: {max_date}")
    
    def determine_status(self, case_no, in_entries, out_entries):
        """ì¬ê³  ìƒíƒœ ê²°ì •"""
        if out_entries:
            # ì¶œê³  ê¸°ë¡ì´ ìˆìœ¼ë©´ OUT
            out_dates = [entry[0] for entry in out_entries if entry[0]]
            return "OUT (by OUTsheet)", f"OutDates: {', '.join(out_dates)}"
        
        elif in_entries:
            # ì…ê³  ê¸°ë¡ë§Œ ìˆëŠ” ê²½ìš° - ìµœì‹  ìŠ¤ëƒ…ìƒ·ê³¼ ë¹„êµ
            sorted_entries = sorted(in_entries, key=lambda x: x[0])
            last_seen_str = sorted_entries[-1][0]
            
            try:
                last_seen_date = datetime.strptime(last_seen_str, '%Y-%m-%d').date()
                
                if self.global_max_date and last_seen_date < self.global_max_date:
                    return "OUT (absent in latest snapshot)", \
                           f"LastSeen: {last_seen_str} ; GlobalLatest: {self.global_max_date}"
                else:
                    return "IN", ""
            except:
                return "IN", ""
        
        else:
            return "UNKNOWN", ""
    
    def create_summary(self):
        """ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±"""
        # ëª¨ë“  CASE ìˆ˜ì§‘
        all_cases = set(self.case_data.keys()) | set(self.out_data.keys())
        
        summary_data = []
        
        for case_no in sorted(all_cases):
            in_entries = sorted(self.case_data.get(case_no, []), key=lambda x: x[0])
            out_entries = sorted(self.out_data.get(case_no, []), key=lambda x: x[0])
            
            # ê¸°ë³¸ ì •ë³´
            count = len(in_entries)
            first_in_date = in_entries[0][0] if in_entries else ""
            all_in_dates = ", ".join([entry[0] for entry in in_entries])
            last_seen = in_entries[-1][0] if in_entries else ""
            last_location = in_entries[-1][1] if in_entries else ""
            
            # ìƒíƒœ ê²°ì •
            status, note = self.determine_status(case_no, in_entries, out_entries)
            
            summary_data.append({
                'CASE_NO': case_no,
                'Count': count,
                'First_IN_Date': first_in_date,
                'All_IN_Dates': all_in_dates,
                'LastSeen': last_seen,
                'Last_Location': last_location,
                'Status': status,
                'Note': note
            })
        
        return pd.DataFrame(summary_data)
    
    def save_summary_to_excel(self, output_file=None):
        """ìš”ì•½ ê²°ê³¼ë¥¼ Excel íŒŒì¼ë¡œ ì €ì¥"""
        if output_file is None:
            output_file = self.excel_file.replace('.xlsx', '_with_summary.xlsx')
        
        try:
            # ê¸°ì¡´ ì›Œí¬ë¶ ë³µì‚¬
            wb = openpyxl.load_workbook(self.excel_file)
            
            # ê¸°ì¡´ Onhand_Summary ì‹œíŠ¸ ì‚­ì œ (ìˆë‹¤ë©´)
            if 'Onhand_Summary' in wb.sheetnames:
                wb.remove(wb['Onhand_Summary'])
            
            # ìƒˆ ìš”ì•½ ì‹œíŠ¸ ìƒì„±
            summary_df = self.create_summary()
            ws = wb.create_sheet('Onhand_Summary')
            
            # ë°ì´í„°í”„ë ˆì„ì„ ì‹œíŠ¸ì— ì“°ê¸°
            for r in dataframe_to_rows(summary_df, index=False, header=True):
                ws.append(r)
            
            # ì»¬ëŸ¼ ë„ˆë¹„ ìë™ ì¡°ì •
            for column in ws.columns:
                max_length = 0
                column_letter = column[0].column_letter
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                adjusted_width = min(max_length + 2, 50)
                ws.column_dimensions[column_letter].width = adjusted_width
            
            wb.save(output_file)
            print(f"âœ… ìš”ì•½ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_file}")
            print(f"ğŸ“Š ì´ {len(summary_df)}ê±´ ì²˜ë¦¬")
            return output_file
            
        except Exception as e:
            print(f"âŒ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
            return None
    
    def run_analysis(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        print("ğŸš€ ì¬ê³  ì¶”ì  ë¶„ì„ ì‹œì‘...")
        
        # 1. ì›Œí¬ë¶ ë¡œë“œ
        if not self.load_workbook():
            return None
        
        # 2. ëª¨ë“  ì‹œíŠ¸ ì²˜ë¦¬
        print("\nğŸ“‚ ì‹œíŠ¸ ì²˜ë¦¬ ì¤‘...")
        for sheet_name in self.workbook.sheet_names:
            if sheet_name not in ['Onhand_Summary']:  # ìš”ì•½ ì‹œíŠ¸ ì œì™¸
                self.process_sheet(sheet_name)
        
        # 3. ì „ì—­ ìµœì‹  ë‚ ì§œ ê³„ì‚°
        print("\nğŸ“… ë‚ ì§œ ë¶„ì„ ì¤‘...")
        self.calculate_global_max_date()
        
        # 4. ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„± ë° ì €ì¥
        print("\nğŸ“‹ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        return self.save_summary_to_excel()
    
    def get_status_summary(self):
        """ìƒíƒœë³„ ìš”ì•½ í†µê³„"""
        summary_df = self.create_summary()
        status_counts = summary_df['Status'].value_counts()
        
        print("\nğŸ“ˆ ìƒíƒœë³„ í†µê³„:")
        for status, count in status_counts.items():
            print(f"   {status}: {count}ê±´")
        
        return status_counts


# ì‚¬ìš© ì˜ˆì‹œ ë° ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def main(excel_file_path):
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    
    Args:
        excel_file_path (str): ë¶„ì„í•  Excel íŒŒì¼ ê²½ë¡œ
    
    Returns:
        str: ìƒì„±ëœ ìš”ì•½ íŒŒì¼ ê²½ë¡œ
    """
    tracker = InventoryTracker(excel_file_path)
    
    # ë¶„ì„ ì‹¤í–‰
    output_file = tracker.run_analysis()
    
    if output_file:
        # ìƒíƒœë³„ í†µê³„ ì¶œë ¥
        tracker.get_status_summary()
        
        # ìš”ì•½ ë°ì´í„°í”„ë ˆì„ ë¯¸ë¦¬ë³´ê¸°
        summary_df = tracker.create_summary()
        print(f"\nğŸ“‹ ìš”ì•½ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 10ê±´):")
        print(summary_df.head(10).to_string(index=False))
        
        return output_file
    else:
        print("âŒ ë¶„ì„ ì‹¤íŒ¨")
        return None

# ì§ì ‘ ì‹¤í–‰ ì‹œ í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    # HVDC í”„ë¡œì íŠ¸ ì¬ê³  ë°ì´í„° ë¶„ì„ - í†µí•©ë¶„ì„ íŒŒì¼
    test_file = r"HVDC WH DATA\Stock On Hand Report_í†µí•©ë¶„ì„_20250919_1604.xlsx"
    
    print("=" * 60)
    print("ğŸ­ HVDC í”„ë¡œì íŠ¸ ì¬ê³  ì¶”ì  ì‹œìŠ¤í…œ v2.0")
    print("=" * 60)
    
    result = main(test_file)
    
    if result:
        print(f"\nğŸ‰ ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ íŒŒì¼: {result}")
    else:
        print("âŒ ë¶„ì„ ì‹¤íŒ¨")